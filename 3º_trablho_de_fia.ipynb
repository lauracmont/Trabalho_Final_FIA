{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Fundamentos Teóricos: NeSy e Lógica Tensorial (LTN)\n",
        "\n",
        "## O que é Raciocínio Neuro-Simbólico (NeSy)?\n",
        "\n",
        "O Raciocínio Neuro-Simbólico (NeSy) é uma área de pesquisa que busca combinar os pontos fortes da **Inteligência Artificial Simbólica** (raciocínio lógico, representação explícita de conhecimento) com os da **Aprendizagem Profunda (Deep Learning)** (percepção robusta, tolerância a ruído). O objetivo é criar sistemas que possam perceber o mundo de forma neural, mas raciocinar sobre ele de forma lógica e interpretável.\n",
        "\n",
        "## Lógica Tensorial (LTN - Logic Tensor Networks)\n",
        "\n",
        "LTN é uma arquitetura de NeSy que implementa a Lógica de Primeira Ordem (First-Order Logic - FOL) dentro de redes neurais, transformando o raciocínio lógico em um problema de otimização contínua.\n",
        "\n",
        "* **Fundamentação:** LTN mapeia o conceito de \"Verdade\" para o intervalo contínuo $[0, 1]$, onde 1 é totalmente verdadeiro e 0 é totalmente falso.\n",
        "* **Elementos Chave:**\n",
        "    * **Termos:** Objetos (dados brutos, vetores) representados por tensores.\n",
        "    * **Predicados:** Funções neurais (redes neurais) que recebem termos e retornam a satisfatibilidade (grau de verdade) de uma propriedade ou relação, entre 0 e 1.\n",
        "    * **Operadores Lógicos:** Operadores como $\\land$ (E), $\\lor$ (OU), $\\neg$ (NÃO), e $\\Rightarrow$ (IMPLICA) são mapeados para funções contínuas e diferenciáveis (e.g., *t-norms* e *t-conorms*).\n",
        "    * **Raciocínio:** O conhecimento (axiomas) é representado como a média da satisfatibilidade de todas as fórmulas. O treinamento otimiza os pesos da rede neural para maximizar essa satisfatibilidade média agregada ($\\text{SatAgg}$), forçando a rede a aprender predicados que sejam consistentes com as regras lógicas dadas."
      ],
      "metadata": {
        "id": "WD0Ria_Fb-Tp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Dataset e Cenário: CLEVR Simplificado\n",
        "\n",
        "O experimento utiliza um cenário sintético simplificado baseado na estrutura do dataset **CLEVR (Compositional Language and Elementary Visual Reasoning)**, um benchmark comum para raciocínio visual e linguístico.\n",
        "\n",
        "## Estrutura do Objeto (Vetores de 11 Atributos)\n",
        "\n",
        "Cada objeto na cena é representado por um vetor de entrada (Termo) de 11 dimensões, normalizado entre 0 e 1:\n",
        "\n",
        "| Índice | Atributo | Normalização/Codificação | Notas |\n",
        "| :---: | :--- | :--- | :--- |\n",
        "| 0 | Posição X | Normalizado por $\\text{Pos}_{\\text{max}}=38.0$ | Usado para Predicados Relacionais (LeftOf, Below). |\n",
        "| 1 | Posição Y | Normalizado por $\\text{Pos}_{\\text{max}}=27.0$ | |\n",
        "| 2-4 | Cor (RGB) | One-hot ou Codificação Soft (e.g., Amarelo = [1, 1, 0]) | Usado para Predicados Unários (IsGreen). |\n",
        "| 5-9 | Forma | One-hot para 5 formas (Círculo, Quadrado, Cilindro, Cone, Triângulo) | Usado para Predicados Unários (IsCylinder). |\n",
        "| 10 | Tamanho | Valor Contínuo: 0.0 (Pequeno), 0.5 (Médio), 1.0 (Grande) | Usado para Predicados Unários (IsSmall). |\n",
        "\n",
        "A simplificação permite que os Predicados (redes neurais) aprendam a relação entre o vetor de atributos e a satisfação lógica, sem a necessidade de uma CNN complexa de percepção inicial."
      ],
      "metadata": {
        "id": "MFfNwECicErX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYREXRwyLULE",
        "outputId": "0f880bf7-cc3f-4a69-c450-74f80ade072c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================== INÍCIO DA EXECUÇÃO 1/5 ====================\n",
            "Pré-Treinamento iniciado com 25 objetos fixos por 50 epochs...\n",
            "Gerando plotagem do cenário Fixo de Pré-Treinamento (Requisito 1)...\n",
            "Pré-Treinamento Concluído (SatAgg Final Fixo: 0.7079)\n",
            "Treinamento Principal iniciado com 25 objetos aleatórios por 150 epochs...\n",
            "Treinamento Principal Concluído (SatAgg Final Aleatório: 0.9366)\n",
            "GT Q1: 1, Pred Q1: 0.0029 | GT Q2: 1, Pred Q2: 0.0029\n",
            "\n",
            "==================== INÍCIO DA EXECUÇÃO 2/5 ====================\n",
            "Pré-Treinamento iniciado com 25 objetos fixos por 50 epochs...\n",
            "Pré-Treinamento Concluído (SatAgg Final Fixo: 0.7505)\n",
            "Treinamento Principal iniciado com 25 objetos aleatórios por 150 epochs...\n",
            "Treinamento Principal Concluído (SatAgg Final Aleatório: 0.9355)\n",
            "GT Q1: 1, Pred Q1: 0.0028 | GT Q2: 1, Pred Q2: 0.0041\n",
            "\n",
            "==================== INÍCIO DA EXECUÇÃO 3/5 ====================\n",
            "Pré-Treinamento iniciado com 25 objetos fixos por 50 epochs...\n",
            "Pré-Treinamento Concluído (SatAgg Final Fixo: 0.7179)\n",
            "Treinamento Principal iniciado com 25 objetos aleatórios por 150 epochs...\n",
            "Treinamento Principal Concluído (SatAgg Final Aleatório: 0.9169)\n",
            "GT Q1: 1, Pred Q1: 0.0052 | GT Q2: 1, Pred Q2: 0.0047\n",
            "\n",
            "==================== INÍCIO DA EXECUÇÃO 4/5 ====================\n",
            "Pré-Treinamento iniciado com 25 objetos fixos por 50 epochs...\n",
            "Pré-Treinamento Concluído (SatAgg Final Fixo: 0.7415)\n",
            "Treinamento Principal iniciado com 25 objetos aleatórios por 150 epochs...\n",
            "Treinamento Principal Concluído (SatAgg Final Aleatório: 0.9291)\n",
            "GT Q1: 1, Pred Q1: 0.0024 | GT Q2: 1, Pred Q2: 0.0037\n",
            "\n",
            "==================== INÍCIO DA EXECUÇÃO 5/5 ====================\n",
            "Pré-Treinamento iniciado com 25 objetos fixos por 50 epochs...\n",
            "Pré-Treinamento Concluído (SatAgg Final Fixo: 0.7471)\n",
            "Treinamento Principal iniciado com 25 objetos aleatórios por 150 epochs...\n",
            "Treinamento Principal Concluído (SatAgg Final Aleatório: 0.9332)\n",
            "GT Q1: 1, Pred Q1: 0.0019 | GT Q2: 1, Pred Q2: 0.0019\n",
            "\n",
            "================================================================================\n",
            "RELATÓRIO FINAL DO EXPERIMENTO LTN (5 EXECUÇÕES)\n",
            "LIMITES DE CENA: X=38.0, Y=27.0\n",
            "================================================================================\n",
            "\n",
            "**1. Satisfatibilidade (SatAgg) das Queries Q1 e Q2 e Ground Truth (GT)**\n",
            "|   Run |   SatAgg_Q1 |   GT_Q1 |   SatAgg_Q2 |   GT_Q2 |\n",
            "|------:|------------:|--------:|------------:|--------:|\n",
            "|     1 |      0.0029 |       1 |      0.0029 |       1 |\n",
            "|     2 |      0.0028 |       1 |      0.0041 |       1 |\n",
            "|     3 |      0.0052 |       1 |      0.0047 |       1 |\n",
            "|     4 |      0.0024 |       1 |      0.0037 |       1 |\n",
            "|     5 |      0.0019 |       1 |      0.0019 |       1 |\n",
            "\n",
            "**2. Satisfatibilidade Média Agregada de Raciocínio (Axiomas e Queries Opcionais)**\n",
            "|              |   SatAgg_F1 |   SatAgg_F3 |   SatAgg_F6 |   SatAgg_Q3 |   SatAgg_LastLeft |   SatAgg_Existencial |\n",
            "|:-------------|------------:|------------:|------------:|------------:|------------------:|---------------------:|\n",
            "| SatAgg Média |      0.7347 |      0.9995 |      0.9033 |      0.9993 |            0.0005 |               0.9956 |\n",
            "\n",
            "**3. Métricas de Classificação Agregadas (Limiar de Decisão: SatAgg > 0.55)**\n",
            "| Métrica   |   Query 1 (Q1) |   Query 2 (Q2) |\n",
            "|:----------|---------------:|---------------:|\n",
            "| Acurácia  |              0 |              0 |\n",
            "| Precisão  |              0 |              0 |\n",
            "| Recall    |              0 |              0 |\n",
            "| F1 Score  |              0 |              0 |\n",
            "\n",
            "================================================================================\n",
            "4. ANÁLISE EXPLICATIVA DO RACIOCÍNIO LTN\n",
            "================================================================================\n",
            "### Pergunta 1: Filtragem Composta\n",
            "Fórmula: $\\exists x(\\text{IsSmall}(x) \\land \\exists y(\\text{IsCylinder}(y) \\land \\text{Below}(x, y)) \\land \\exists z(\\text{IsSquare}(z) \\land \\text{LeftOf}(x, z)))$\n",
            "GT Média: 1.00 | SatAgg Média: 0.0030\n",
            "\n",
            "Raciocínio: A rede deve encontrar um único objeto (x) que satisfaça três condições complexas simultaneamente: (1) ser Pequeno, (2) estar Abaixo de algum Cilindro, E (3) estar à Esquerda de algum Quadrado.\n",
            "\n",
            "Conclusão: O valor de SatAgg Média (0.0030) é extremamente baixo e **inconsistente** com o Ground Truth (1.00). A falha indica que a rede neural, apesar do alto SatAgg nos axiomas gerais, falhou em **combinar** com sucesso o predicado 'IsSmall' com os dois predicados relacionais ('Below' e 'LeftOf') em um único objeto 'x'. Isso sugere que a cadeia de raciocínio complexa não foi generalizada adequadamente no treinamento, resultando em F1 Score de 0.0000.\n",
            "\n",
            "### Pergunta 2: Dedução de Posição Absoluta\n",
            "Fórmula: $\\exists x, y, z(\\text{IsCone}(x) \\land \\text{IsGreen}(x) \\land \\text{InBetween}(x, y, z))$\n",
            "GT Média: 1.00 | SatAgg Média: 0.0035\n",
            "\n",
            "Raciocínio: A rede deve provar a existência de um Cone de cor Verde que se localize 'Entre' quaisquer outros dois objetos (y e z). Como 'InBetween' é definido pela lógica horizontal ($\text{LeftOf}$ e $\text{RightOf}$), a prova depende de encontrar um Cone Verde que esteja horizontalmente entre outros dois.\n",
            "\n",
            "Conclusão: O SatAgg Média (0.0035) é **extremamente baixo**, resultando em Acurácia de 0.0000 e F1 Score de 0.0000. A falha é esperada, pois o predicado 'InBetween' é uma **fórmula lógica fixa** baseada em 'LeftOf' e 'RightOf'. A baixíssima satisfação reflete a dificuldade das NNs em aprender 'LeftOf' e 'RightOf' com precisão (transitividade e simetria) suficiente para satisfazer a lógica combinatória do predicado ternário 'InBetween'.\n",
            "\n",
            "### Restrição de Proximidade (Q3 - Axioma de Treinamento)\n",
            "Fórmula: $\\forall x, y((\\text{IsTriangle}(x) \\land \\text{IsTriangle}(y) \\land \\text{CloseTo}(x, y)) \\Rightarrow \\text{SameSize}(x, y))$\n",
            "SatAgg Média (Fim do Treinamento): 0.9993\n",
            "\n",
            "Raciocínio: Este axioma força o modelo a correlacionar a posição espacial ('CloseTo', fixo pelo Kernel Gaussiano) com um atributo ('SameSize', um predicado neural). Se dois triângulos são próximos, o modelo é penalizado se eles não tiverem o mesmo tamanho.\n",
            "\n",
            "Conclusão: O SatAgg alto (próximo a 1.0) demonstra que a rede neural **aprendeu com sucesso** a codificar a restrição de tamanho para triângulos próximos. O treinamento forçou o predicado 'SameSize' a ser consistente com a proximidade física.\n",
            "\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENTO CONCLUÍDO.\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import textwrap\n",
        "import platform # NOVO: Para checar o sistema operacional\n",
        "\n",
        "# -------------------------------------------------------------------------------\n",
        "# ** ADIÇÃO PARA COMPATIBILIDADE COLAB/TERMINAL **\n",
        "# -------------------------------------------------------------------------------\n",
        "# Tenta definir um backend seguro (Agg) para evitar erros de ambiente gráfico\n",
        "# em servidores ou terminais sem GUI (headless).\n",
        "try:\n",
        "    if 'linux' in platform.platform().lower() and 'jupyter' not in sys.modules:\n",
        "        plt.switch_backend('Agg')\n",
        "except Exception:\n",
        "    pass\n",
        "# -------------------------------------------------------------------------------\n",
        "# 0. CONFIGURAÇÃO E SETUP\n",
        "# -------------------------------------------------------------------------------\n",
        "SEED = 42\n",
        "N_RUNS = 5\n",
        "NUM_OBJECTS = 25\n",
        "POS_RANGE_X, POS_RANGE_Y = 38.0, 27.0\n",
        "SAT_THRESHOLD = 0.55\n",
        "EPOCHS_FIXED = 50\n",
        "EPOCHS_RANDOM = 150\n",
        "LEARNING_RATE = 0.001\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "VECTOR_DIM = 11\n",
        "IDX_X, IDX_Y = 0, 1\n",
        "IDX_R, IDX_G, IDX_B = 2, 3, 4\n",
        "IDX_CIR, IDX_SQU, IDX_CYL, IDX_CON, IDX_TRI = 5, 6, 7, 8, 9\n",
        "IDX_SIZE = 10\n",
        "\n",
        "SHAPES = ['circulo', 'quadrado', 'cilindro', 'cone', 'triangulo']\n",
        "COLORS_BASIC = ['vermelho', 'verde', 'azul']\n",
        "COLORS_EXTENDED = COLORS_BASIC + ['roxo', 'amarelo']\n",
        "SIZES = [0.0, 0.5, 1.0]\n",
        "\n",
        "MAP_ATTR_TO_IDX = {\n",
        "    'vermelho': IDX_R, 'verde': IDX_G, 'azul': IDX_B,\n",
        "    'circulo': IDX_CIR, 'quadrado': IDX_SQU, 'cilindro': IDX_CYL, 'cone': IDX_CON, 'triangulo': IDX_TRI,\n",
        "    'pequeno': 0.0, 'medio': 0.5, 'grande': 1.0\n",
        "}\n",
        "\n",
        "# -------------------------------------------------------------------------------\n",
        "# 1. IMPLEMENTAÇÃO SIMPLIFICADA DO LTN\n",
        "# -------------------------------------------------------------------------------\n",
        "\n",
        "class Predicate(nn.Module):\n",
        "    instances = []\n",
        "\n",
        "    def __init__(self, neural_network: nn.Module = None, lambda_function = None):\n",
        "        super(Predicate, self).__init__()\n",
        "        self.nn = neural_network\n",
        "        self.lambda_fn = lambda_function\n",
        "        Predicate.instances.append(self)\n",
        "\n",
        "    @classmethod\n",
        "    def lambda_op(cls, lambda_function):\n",
        "        return cls(neural_network=None, lambda_function=lambda_function)\n",
        "\n",
        "    def forward(self, *args):\n",
        "        if self.lambda_fn:\n",
        "            result = self.lambda_fn(*args)\n",
        "            if result.dim() == 1:\n",
        "                return result.unsqueeze(-1)\n",
        "            return result\n",
        "\n",
        "        if self.nn:\n",
        "            inputs = torch.cat(args, dim=-1)\n",
        "            return self.nn(inputs)\n",
        "\n",
        "        raise ValueError(\"O predicado deve ter uma NN ou uma função lambda definida.\")\n",
        "\n",
        "    def parameters(self):\n",
        "        return self.nn.parameters() if self.nn else []\n",
        "\n",
        "# Operadores Lógicos e Quantificadores\n",
        "And = lambda *args: torch.min(torch.stack(args), dim=0)[0]\n",
        "Not = lambda x: 1.0 - x\n",
        "Or = lambda *args: torch.max(torch.stack(args), dim=0)[0]\n",
        "Implies = lambda a, b: torch.max(Not(a), b)\n",
        "Equiv = lambda a, b: And(Implies(a, b), Implies(b, a))\n",
        "Forall = lambda formula: torch.mean(formula)\n",
        "Exists = lambda formula: torch.max(formula)\n",
        "\n",
        "# -------------------------------------------------------------------------------\n",
        "# 2. FUNÇÕES DE GERAÇÃO DE DADOS, PLOTAGEM E MODELOS NN\n",
        "# -------------------------------------------------------------------------------\n",
        "\n",
        "def create_object_vector(obj_data):\n",
        "    vector = torch.zeros(VECTOR_DIM, dtype=torch.float32)\n",
        "    vector[IDX_X] = obj_data['pos'][0] / POS_RANGE_X\n",
        "    vector[IDX_Y] = obj_data['pos'][1] / POS_RANGE_Y\n",
        "    color_map = {'vermelho': IDX_R, 'verde': IDX_G, 'azul': IDX_B}\n",
        "    if obj_data['cor'] in color_map: vector[color_map[obj_data['cor']]] = 1.0\n",
        "    shape_map = {'circulo': IDX_CIR, 'quadrado': IDX_SQU, 'cilindro': IDX_CYL, 'cone': IDX_CON, 'triangulo': IDX_TRI}\n",
        "    vector[shape_map[obj_data['forma']]] = 1.0\n",
        "    vector[IDX_SIZE] = MAP_ATTR_TO_IDX[obj_data['size']]\n",
        "    return vector\n",
        "\n",
        "def generate_random_dataset(num_objects):\n",
        "    objects = []\n",
        "    for shape in SHAPES:\n",
        "        for _ in range(num_objects // len(SHAPES)):\n",
        "            obj_data = {\n",
        "                'forma': shape, 'cor': random.choice(COLORS_BASIC),\n",
        "                'pos': (random.uniform(1.0, POS_RANGE_X - 1.0), random.uniform(1.0, POS_RANGE_Y - 1.0)),\n",
        "                'size': random.choice(['pequeno', 'medio', 'grande']),\n",
        "            }\n",
        "            objects.append(obj_data)\n",
        "    random.shuffle(objects)\n",
        "    all_vectors = [create_object_vector(obj) for obj in objects]\n",
        "    dataset_tensor = torch.stack(all_vectors).to(DEVICE)\n",
        "    data_df = pd.DataFrame(objects)\n",
        "    return data_df, dataset_tensor\n",
        "\n",
        "def create_fixed_dataset():\n",
        "    fixed_data = [\n",
        "        {'id': 'O1', 'forma': 'quadrado', 'cor_raw': 'amarelo', 'cor': [1.0, 1.0, 0.0], 'pos': (15.0, 18.0), 'size': 'medio'},\n",
        "        {'id': 'O2', 'forma': 'quadrado', 'cor_raw': 'roxo', 'cor': [1.0, 0.0, 1.0], 'pos': (36.0, 26.0), 'size': 'pequeno'},\n",
        "        {'id': 'O10', 'forma': 'quadrado', 'cor_raw': 'vermelho', 'cor': [1.0, 0.0, 0.0], 'pos': (25.5, 25.5), 'size': 'medio'},\n",
        "        {'id': 'O11', 'forma': 'quadrado', 'cor_raw': 'azul', 'cor': [0.0, 0.0, 1.0], 'pos': (10.5, 23.5), 'size': 'grande'},\n",
        "        {'id': 'O16', 'forma': 'quadrado', 'cor_raw': 'verde', 'cor': [0.0, 1.0, 0.0], 'pos': (35.5, 22.5), 'size': 'pequeno'},\n",
        "        {'id': 'O19', 'forma': 'circulo', 'cor_raw': 'azul', 'cor': [0.0, 0.0, 1.0], 'pos': (15.5, 22.5), 'size': 'medio'},\n",
        "        {'id': 'O20', 'forma': 'circulo', 'cor_raw': 'amarelo', 'cor': [1.0, 1.0, 0.0], 'pos': (36.0, 17.0), 'size': 'grande'},\n",
        "        {'id': 'O15', 'forma': 'circulo', 'cor_raw': 'verde', 'cor': [0.0, 1.0, 0.0], 'pos': (9.0, 17.0), 'size': 'pequeno'},\n",
        "        {'id': 'O17', 'forma': 'circulo', 'cor_raw': 'roxo', 'cor': [1.0, 0.0, 1.0], 'pos': (10.5, 3.0), 'size': 'medio'},\n",
        "        {'id': 'O18', 'forma': 'circulo', 'cor_raw': 'vermelho', 'cor': [1.0, 0.0, 0.0], 'pos': (21.5, 2.5), 'size': 'pequeno'},\n",
        "        {'id': 'O14', 'forma': 'triangulo', 'cor_raw': 'verde', 'cor': [0.0, 1.0, 0.0], 'pos': (25.0, 10.0), 'size': 'pequeno'},\n",
        "        {'id': 'O25', 'forma': 'triangulo', 'cor_raw': 'amarelo', 'cor': [1.0, 1.0, 0.0], 'pos': (26.0, 18.0), 'size': 'medio'},\n",
        "        {'id': 'O5', 'forma': 'triangulo', 'cor_raw': 'azul', 'cor': [0.0, 0.0, 1.0], 'pos': (15.0, 25.5), 'size': 'pequeno'},\n",
        "        {'id': 'O3', 'forma': 'triangulo', 'cor_raw': 'vermelho', 'cor': [1.0, 0.0, 0.0], 'pos': (17.0, 2.0), 'size': 'pequeno'},\n",
        "        {'id': 'O23', 'forma': 'triangulo', 'cor_raw': 'roxo', 'cor': [1.0, 0.0, 1.0], 'pos': (30.0, 23.0), 'size': 'grande'},\n",
        "        {'id': 'O22', 'forma': 'cone', 'cor_raw': 'roxo', 'cor': [1.0, 0.0, 1.0], 'pos': (2.5, 17.0), 'size': 'medio'},\n",
        "        {'id': 'O6', 'forma': 'cone', 'cor_raw': 'amarelo', 'cor': [1.0, 1.0, 0.0], 'pos': (4.0, 6.0), 'size': 'medio'},\n",
        "        {'id': 'O21', 'forma': 'cone', 'cor_raw': 'vermelho', 'cor': [1.0, 0.0, 0.0], 'pos': (33.0, 6.0), 'size': 'grande'},\n",
        "        {'id': 'O12', 'forma': 'cone', 'cor_raw': 'azul', 'cor': [0.0, 0.0, 1.0], 'pos': (31.5, 17.0), 'size': 'medio'},\n",
        "        {'id': 'O8', 'forma': 'cone', 'cor_raw': 'verde', 'cor': [0.0, 1.0, 0.0], 'pos': (12.0, 9.0), 'size': 'pequeno'},\n",
        "        {'id': 'O24', 'forma': 'cilindro', 'cor_raw': 'azul', 'cor': [0.0, 0.0, 1.0], 'pos': (24.5, 4.0), 'size': 'grande'},\n",
        "        {'id': 'O7', 'forma': 'cilindro', 'cor_raw': 'amarelo', 'cor': [1.0, 1.0, 0.0], 'pos': (37.5, 10.0), 'size': 'medio'},\n",
        "        {'id': 'O13', 'forma': 'cilindro', 'cor_raw': 'vermelho', 'cor': [1.0, 0.0, 0.0], 'pos': (6.5, 10.0), 'size': 'pequeno'},\n",
        "        {'id': 'O4', 'forma': 'cilindro', 'cor_raw': 'roxo', 'cor': [1.0, 0.0, 1.0], 'pos': (5.0, 24.0), 'size': 'medio'},\n",
        "        {'id': 'O9', 'forma': 'cilindro', 'cor_raw': 'verde', 'cor': [0.0, 1.0, 0.0], 'pos': (2.0, 12.0), 'size': 'medio'},\n",
        "    ]\n",
        "\n",
        "    def create_vector_fixed(obj_data):\n",
        "        vector = torch.zeros(VECTOR_DIM, dtype=torch.float32)\n",
        "        vector[IDX_X] = obj_data['pos'][0] / POS_RANGE_X\n",
        "        vector[IDX_Y] = obj_data['pos'][1] / POS_RANGE_Y\n",
        "        vector[IDX_R:IDX_B + 1] = torch.tensor(obj_data['cor'])\n",
        "        shape_map = {'circulo': IDX_CIR, 'quadrado': IDX_SQU, 'cilindro': IDX_CYL, 'cone': IDX_CON, 'triangulo': IDX_TRI}\n",
        "        vector[shape_map[obj_data['forma']]] = 1.0\n",
        "        vector[IDX_SIZE] = MAP_ATTR_TO_IDX[obj_data['size']]\n",
        "        return vector\n",
        "\n",
        "    all_vectors = [create_vector_fixed(obj) for obj in fixed_data]\n",
        "    dataset_tensor = torch.stack(all_vectors).to(DEVICE)\n",
        "    data_df = pd.DataFrame(fixed_data)\n",
        "    data_df['cor'] = data_df['cor_raw']\n",
        "\n",
        "    return data_df, dataset_tensor\n",
        "\n",
        "def plot_scenario(data_df, title=\"Cenário Aleatório CLEVR-like\"):\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    color_map_plot = {'vermelho': 'red', 'verde': 'green', 'azul': 'blue','roxo': 'purple', 'amarelo': 'yellow' }\n",
        "    size_map = {'pequeno': 100, 'medio': 300, 'grande': 600}\n",
        "    shape_map = {'circulo': 'o', 'quadrado': 's', 'cilindro': 'D', 'cone': '^', 'triangulo': 'v'}\n",
        "    for index, row in data_df.iterrows():\n",
        "        x, y = row['pos']\n",
        "        color = color_map_plot.get(row['cor'], 'black')\n",
        "        size = size_map.get(row['size'], 200)\n",
        "        marker = shape_map.get(row['forma'], 'x')\n",
        "        plt.scatter(x, y, s=size, c=color, marker=marker, alpha=0.7, edgecolors='black', linewidth=1)\n",
        "        plt.text(x + 0.5, y + 0.5, row.get('id', str(index+1)), fontsize=8)\n",
        "    plt.xlim(0, POS_RANGE_X)\n",
        "    plt.ylim(0, POS_RANGE_Y)\n",
        "    plt.title(title, fontsize=14)\n",
        "    plt.xlabel(\"Posição X (Máximo: 38)\"); plt.ylabel(\"Posição Y (Máximo: 27)\")\n",
        "    plt.grid(True, linestyle='--', alpha=0.5)\n",
        "    legend_handles = []\n",
        "    for name, color_code in color_map_plot.items():\n",
        "        legend_handles.append(plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=color_code, markersize=10, label=f'Cor: {name.capitalize()}'))\n",
        "    legend_handles.append(plt.Line2D([0], [0], linestyle='none', label=''))\n",
        "    for name, marker_code in shape_map.items():\n",
        "        legend_handles.append(plt.Line2D([0], [0], marker=marker_code, color='w', markerfacecolor='gray', markersize=10, label=f'Forma: {name.capitalize()}'))\n",
        "    legend_handles.append(plt.Line2D([0], [0], linestyle='none', label=''))\n",
        "    for name, size_val in size_map.items():\n",
        "        legend_handles.append(plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='gray', markersize=np.sqrt(size_val)/4, label=f'Tamanho: {name.capitalize()}'))\n",
        "    plt.legend(handles=legend_handles, loc='upper left', bbox_to_anchor=(1.05, 1), title=\"Legenda de Atributos\", fontsize=9)\n",
        "    # plt.show() - A chamada é removida ou comentada aqui para evitar bloqueio em ambiente GUI\n",
        "\n",
        "    # Em Colab/Jupyter, plt.show() é implícito. Se estiver em modo 'Agg', esta linha salva a figura.\n",
        "    # No entanto, no nosso caso, a chamada à plt.show() é necessária para mostrar no Colab.\n",
        "    # Como adicionamos a lógica de segurança no topo, podemos manter plt.show()\n",
        "    # pois o backend Agg irá ignorá-lo ou salvá-lo sem travar, e no Colab ele funcionará.\n",
        "    plt.tight_layout(rect=[0, 0, 1.0, 1]); plt.show()\n",
        "\n",
        "\n",
        "def hard_LeftOf(pos1, pos2): return 1 if pos1[0] < pos2[0] else 0\n",
        "def hard_Below(pos1, pos2): return 1 if pos1[1] < pos2[1] else 0\n",
        "def hard_InBetween(pos_x, pos_y, pos_z):\n",
        "    x_x = pos_x[0]\n",
        "    y_x, z_x = pos_y[0], pos_z[0]\n",
        "    between_x = (min(y_x, z_x) < x_x < max(y_x, z_x))\n",
        "    return 1 if between_x else 0\n",
        "\n",
        "def calculate_ground_truth(data_df):\n",
        "    is_small_gt = data_df['size'] == 'pequeno'\n",
        "    is_cylinder_gt = data_df['forma'] == 'cilindro'\n",
        "    is_square_gt = data_df['forma'] == 'quadrado'\n",
        "    is_cone_gt = data_df['forma'] == 'cone'\n",
        "    is_green_gt = data_df['cor'] == 'verde'\n",
        "\n",
        "    gt_Q1 = 0\n",
        "    for i in range(len(data_df)):\n",
        "        x_data = data_df.iloc[i]\n",
        "        if not is_small_gt.iloc[i]: continue\n",
        "        found_y = False\n",
        "        for j in range(len(data_df)):\n",
        "            y_data = data_df.iloc[j]\n",
        "            if is_cylinder_gt.iloc[j] and hard_Below(x_data['pos'], y_data['pos']):\n",
        "                found_y = True; break\n",
        "        if not found_y: continue\n",
        "        found_z = False\n",
        "        for k in range(len(data_df)):\n",
        "            z_data = data_df.iloc[k]\n",
        "            if is_square_gt.iloc[k] and hard_LeftOf(x_data['pos'], z_data['pos']):\n",
        "                found_z = True; break\n",
        "        if found_y and found_z: gt_Q1 = 1; break\n",
        "\n",
        "    gt_Q2 = 0\n",
        "    for i in range(len(data_df)):\n",
        "        x_data = data_df.iloc[i]\n",
        "        if is_cone_gt.iloc[i] and is_green_gt.iloc[i]:\n",
        "            for j in range(len(data_df)):\n",
        "                if i == j: continue\n",
        "                y_data = data_df.iloc[j]\n",
        "                for k in range(len(data_df)):\n",
        "                    if k == i or k == j: continue\n",
        "                    z_data = data_df.iloc[k]\n",
        "                    if hard_InBetween(x_data['pos'], y_data['pos'], z_data['pos']): gt_Q2 = 1; break\n",
        "                if gt_Q2 == 1: break\n",
        "        if gt_Q2 == 1: break\n",
        "\n",
        "    return gt_Q1, gt_Q2\n",
        "\n",
        "\n",
        "class AttributeNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AttributeNN, self).__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(VECTOR_DIM, 32), nn.LeakyReLU(0.1),\n",
        "            nn.Linear(32, 16), nn.LeakyReLU(0.1),\n",
        "            nn.Linear(16, 1), nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "class RelationNN(nn.Module):\n",
        "    def __init__(self, num_inputs=2):\n",
        "        super(RelationNN, self).__init__()\n",
        "        input_dim = num_inputs * VECTOR_DIM\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(input_dim, 64), nn.LeakyReLU(0.1),\n",
        "            nn.Linear(64, 32), nn.LeakyReLU(0.1),\n",
        "            nn.Linear(32, 1), nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "def setup_predicates():\n",
        "    Predicate.instances = []\n",
        "    P = {}\n",
        "\n",
        "    # Predicados Unários (NNs Treináveis)\n",
        "    for name in COLORS_BASIC + SHAPES:\n",
        "        P[f'Is{name.capitalize()}'] = Predicate(AttributeNN()).to(DEVICE)\n",
        "    P['IsSmall'] = Predicate(AttributeNN()).to(DEVICE)\n",
        "    P['IsMedium'] = Predicate(AttributeNN()).to(DEVICE)\n",
        "    P['IsBig'] = Predicate(AttributeNN()).to(DEVICE)\n",
        "\n",
        "    # Predicados Relacionais Treináveis (NNs)\n",
        "    P['LeftOf'] = Predicate(RelationNN(num_inputs=2)).to(DEVICE)\n",
        "    P['RightOf'] = Predicate(RelationNN(num_inputs=2)).to(DEVICE)\n",
        "    P['Below'] = Predicate(RelationNN(num_inputs=2)).to(DEVICE)\n",
        "    P['Above'] = Predicate(RelationNN(num_inputs=2)).to(DEVICE)\n",
        "    P['SameSize'] = Predicate(RelationNN(num_inputs=2)).to(DEVICE)\n",
        "    P['SameShape'] = Predicate(RelationNN(num_inputs=2)).to(DEVICE)\n",
        "    P['SameColor'] = Predicate(RelationNN(num_inputs=2)).to(DEVICE)\n",
        "\n",
        "    # Predicados Fixos (lambda_op)\n",
        "    P['CloseTo'] = Predicate.lambda_op(\n",
        "        lambda x, y: torch.exp(-2.0 * torch.sum((x[..., IDX_X:IDX_Y+1] - y[..., IDX_X:IDX_Y+1])**2, dim=-1))\n",
        "    )\n",
        "\n",
        "    LeftOf = P['LeftOf']\n",
        "    RightOf = P['RightOf']\n",
        "\n",
        "    P['InBetween'] = Predicate.lambda_op(\n",
        "        lambda x, y, z: Or(\n",
        "            And(LeftOf(y, x), RightOf(z, x)),\n",
        "            And(LeftOf(z, x), RightOf(y, x))\n",
        "        )\n",
        "    )\n",
        "\n",
        "    return P\n",
        "\n",
        "def get_attribute_grounding(obj_vector, idx):\n",
        "    return obj_vector[..., idx].unsqueeze(-1)\n",
        "\n",
        "def size_similarity(obj_vector, target_value, sigma=0.05):\n",
        "    size_val = obj_vector[..., IDX_SIZE].unsqueeze(-1)\n",
        "    return torch.exp(-torch.pow(size_val - target_value, 2) / (2 * sigma**2))\n",
        "\n",
        "def compute_axioms(objects_tensor, P):\n",
        "    axioms_values = []\n",
        "    n_objects = objects_tensor.shape[0]\n",
        "\n",
        "    # --- 3.1 Axiomas de Grounding ---\n",
        "    for name, idx in MAP_ATTR_TO_IDX.items():\n",
        "        if isinstance(idx, int) and name in COLORS_BASIC + SHAPES:\n",
        "            predicate = P[f'Is{name.capitalize()}']\n",
        "            axiom = Equiv(predicate(objects_tensor), get_attribute_grounding(objects_tensor, idx))\n",
        "            axioms_values.append(Forall(axiom))\n",
        "\n",
        "    axioms_values.append(Forall(Equiv(P['IsSmall'](objects_tensor), size_similarity(objects_tensor, 0.0))))\n",
        "    axioms_values.append(Forall(Equiv(P['IsMedium'](objects_tensor), size_similarity(objects_tensor, 0.5))))\n",
        "    axioms_values.append(Forall(Equiv(P['IsBig'](objects_tensor), size_similarity(objects_tensor, 1.0))))\n",
        "\n",
        "    # --- 3.2 Axiomas de Taxonomia ---\n",
        "    all_shapes_pred = torch.stack([P[f'Is{s.capitalize()}'](objects_tensor) for s in SHAPES])\n",
        "    for i in range(len(SHAPES)):\n",
        "        for j in range(i + 1, len(SHAPES)):\n",
        "            excl_formula = Not(And(all_shapes_pred[i], all_shapes_pred[j]))\n",
        "            axioms_values.append(Forall(excl_formula))\n",
        "\n",
        "    coverage_formula = Or(*[P[f'Is{s.capitalize()}'](objects_tensor) for s in SHAPES])\n",
        "    axioms_values.append(Forall(coverage_formula))\n",
        "\n",
        "    # --- 3.3 Axiomas de Raciocínio ---\n",
        "    x_all = objects_tensor.unsqueeze(1).repeat(1, n_objects, 1).view(-1, VECTOR_DIM)\n",
        "    y_all = objects_tensor.unsqueeze(0).repeat(n_objects, 1, 1).view(-1, VECTOR_DIM)\n",
        "    x_all3 = objects_tensor.unsqueeze(1).unsqueeze(2).repeat(1, n_objects, n_objects, 1).view(-1, VECTOR_DIM)\n",
        "    y_all3 = objects_tensor.unsqueeze(0).unsqueeze(2).repeat(n_objects, 1, n_objects, 1).view(-1, VECTOR_DIM)\n",
        "    z_all3 = objects_tensor.unsqueeze(0).unsqueeze(1).repeat(n_objects, n_objects, 1, 1).view(-1, VECTOR_DIM)\n",
        "\n",
        "    # Raciocínio Horizontal\n",
        "    not_left_of_self = Not(P['LeftOf'](objects_tensor, objects_tensor))\n",
        "    axioms_values.append(Forall(not_left_of_self))\n",
        "    asymmetry_formula = Implies(P['LeftOf'](x_all, y_all), Not(P['LeftOf'](y_all, x_all)))\n",
        "    axioms_values.append(Forall(asymmetry_formula))\n",
        "    inverse_h_formula = Equiv(P['LeftOf'](x_all, y_all), P['RightOf'](y_all, x_all))\n",
        "    axioms_values.append(Forall(inverse_h_formula))\n",
        "    antecedent_trans = And(P['LeftOf'](x_all3, y_all3), P['LeftOf'](y_all3, z_all3))\n",
        "    transitivity_formula = Implies(antecedent_trans, P['LeftOf'](x_all3, z_all3))\n",
        "    axioms_values.append(Forall(transitivity_formula))\n",
        "\n",
        "    # Restrição Quadrado-Círculo\n",
        "    antecedent_sc = And(P['IsQuadrado'](x_all), P['IsCirculo'](y_all))\n",
        "    sc_formula = Implies(antecedent_sc, P['RightOf'](x_all, y_all))\n",
        "    axioms_values.append(Forall(sc_formula))\n",
        "\n",
        "    # Restrição de Proximidade (Q3 - Requisito)\n",
        "    antecedent_q3 = And(P['IsTriangulo'](x_all), P['IsTriangulo'](y_all), P['CloseTo'](x_all, y_all))\n",
        "    q3_formula = Implies(antecedent_q3, P['SameSize'](x_all, y_all))\n",
        "    axioms_values.append(Forall(q3_formula))\n",
        "\n",
        "    # Raciocínio Vertical\n",
        "    inverse_v_formula = Equiv(P['Below'](x_all, y_all), P['Above'](y_all, x_all))\n",
        "    axioms_values.append(Forall(inverse_v_formula))\n",
        "    antecedent_trans_v = And(P['Below'](x_all3, y_all3), P['Below'](y_all3, z_all3))\n",
        "    transitivity_formula_v = Implies(antecedent_trans_v, P['Below'](x_all3, z_all3))\n",
        "    axioms_values.append(Forall(transitivity_formula_v))\n",
        "\n",
        "    # canStack\n",
        "    y_is_bad_base = Or(P['IsCone'](y_all), P['IsTriangulo'](y_all))\n",
        "    stability_condition = P['SameSize'](x_all, y_all)\n",
        "    full_stability_req = And(Not(y_is_bad_base), stability_condition)\n",
        "    canstack_formula = Implies(P['Below'](x_all, y_all), full_stability_req)\n",
        "    axioms_values.append(Forall(canstack_formula))\n",
        "\n",
        "    # F3: Posição Relativa\n",
        "    f3_formula = Implies(P['Below'](x_all, y_all), Not(P['LeftOf'](x_all, y_all)))\n",
        "    axioms_values.append(Forall(f3_formula))\n",
        "\n",
        "    clean_axioms = []\n",
        "    for val in axioms_values:\n",
        "        val = val.mean().unsqueeze(0)\n",
        "        if torch.all(torch.isfinite(val)):\n",
        "            clean_axioms.append(val)\n",
        "        else:\n",
        "            clean_axioms.append(torch.tensor([0.5]).to(DEVICE))\n",
        "\n",
        "    return clean_axioms\n",
        "\n",
        "def calculate_formulas_sataag(objects_tensor, P):\n",
        "    n_objects = objects_tensor.shape[0]\n",
        "    x_all = objects_tensor.unsqueeze(1).repeat(1, n_objects, 1).view(-1, VECTOR_DIM)\n",
        "    y_all = objects_tensor.unsqueeze(0).repeat(n_objects, 1, 1).view(-1, VECTOR_DIM)\n",
        "\n",
        "    # Q1\n",
        "    R_xy = And(P['IsCilindro'](y_all), P['Below'](x_all, y_all))\n",
        "    Qy_x = torch.max(R_xy.view(n_objects, n_objects), dim=1)[0].unsqueeze(1)\n",
        "    S_xz = And(P['IsQuadrado'](y_all), P['LeftOf'](x_all, y_all))\n",
        "    Qz_x = torch.max(S_xz.view(n_objects, n_objects), dim=1)[0].unsqueeze(1)\n",
        "    combined_x_Q1 = And(P['IsSmall'](objects_tensor), Qy_x, Qz_x)\n",
        "    sat_Q1 = Exists(combined_x_Q1).item()\n",
        "\n",
        "    # Q2\n",
        "    x_all3 = objects_tensor.unsqueeze(1).unsqueeze(2).repeat(1, n_objects, n_objects, 1).view(-1, VECTOR_DIM)\n",
        "    y_all3 = objects_tensor.unsqueeze(0).unsqueeze(2).repeat(n_objects, 1, n_objects, 1).view(-1, VECTOR_DIM)\n",
        "    z_all3 = objects_tensor.unsqueeze(0).unsqueeze(1).repeat(n_objects, n_objects, 1, 1).view(-1, VECTOR_DIM)\n",
        "\n",
        "    P_xyz_Q2 = And(P['IsCone'](x_all3), P['IsVerde'](x_all3), P['InBetween'](x_all3, y_all3, z_all3))\n",
        "    sat_Q2 = Exists(P_xyz_Q2).item()\n",
        "\n",
        "    # Fórmulas Universais\n",
        "    sat_F1 = Forall(Equiv(P['CloseTo'](x_all, y_all), P['CloseTo'](y_all, x_all))).item()\n",
        "    sat_F3 = Forall(Implies(P['Below'](x_all, y_all), Not(P['LeftOf'](x_all, y_all)))).item()\n",
        "    sat_F6 = Forall(Implies(P['SameShape'](x_all, y_all), P['SameSize'](x_all, y_all))).item()\n",
        "    antecedent_q3 = And(P['IsTriangulo'](x_all), P['IsTriangulo'](y_all), P['CloseTo'](x_all, y_all))\n",
        "    sat_Q3 = Forall(Implies(antecedent_q3, P['SameSize'](x_all, y_all))).item()\n",
        "\n",
        "    # Queries de Quantificadores\n",
        "    left_of_all_y = P['LeftOf'](x_all, y_all).view(n_objects, n_objects)\n",
        "    sat_for_all_y = Forall(left_of_all_y)\n",
        "    sat_last_left = Exists(sat_for_all_y).item()\n",
        "\n",
        "    right_of_all_y = P['RightOf'](x_all, y_all).view(n_objects, n_objects)\n",
        "    sat_for_all_y_right = Forall(right_of_all_y)\n",
        "    sat_last_right = Exists(sat_for_all_y_right).item()\n",
        "\n",
        "    # Consulta Existencial\n",
        "    is_square_y = P['IsQuadrado'](y_all)\n",
        "    left_of_x_y = P['LeftOf'](x_all, y_all)\n",
        "    implication = Implies(is_square_y, left_of_x_y)\n",
        "    forall_y_implication = Forall(implication.view(n_objects, n_objects))\n",
        "    sat_consulta_existencial = Exists(forall_y_implication).item()\n",
        "\n",
        "\n",
        "    return {\n",
        "        'F1': sat_F1, 'F3': sat_F3, 'F6': sat_F6,\n",
        "        'Q3_Axioma': sat_Q3,\n",
        "        'Q1': sat_Q1, 'Q2': sat_Q2,\n",
        "        'lastOnTheLeft': sat_last_left,\n",
        "        'lastOnTheRight': sat_last_right,\n",
        "        'ConsultaExistencial': sat_consulta_existencial\n",
        "    }\n",
        "\n",
        "def calculate_metrics(gt_values, ltn_predictions):\n",
        "    binarized_predictions = [1 if sat > SAT_THRESHOLD else 0 for sat in ltn_predictions]\n",
        "\n",
        "    return {\n",
        "        'Acurácia': accuracy_score(gt_values, binarized_predictions),\n",
        "        'Precisão': precision_score(gt_values, binarized_predictions, zero_division=0),\n",
        "        'Recall': recall_score(gt_values, binarized_predictions, zero_division=0),\n",
        "        'F1 Score': f1_score(gt_values, binarized_predictions, zero_division=0)\n",
        "    }\n",
        "\n",
        "def run_experiment(run_id, epochs_fixed=EPOCHS_FIXED, epochs_random=EPOCHS_RANDOM, lr=LEARNING_RATE):\n",
        "    print(f\"\\n{'='*20} INÍCIO DA EXECUÇÃO {run_id+1}/{N_RUNS} {'='*20}\")\n",
        "\n",
        "    P = setup_predicates()\n",
        "    all_params = []\n",
        "    for pred in Predicate.instances: all_params.extend(pred.parameters())\n",
        "\n",
        "    if not all_params:\n",
        "        print(\"Aviso: Nenhum parâmetro treinável encontrado. Verifique a definição dos predicados.\")\n",
        "        return None\n",
        "\n",
        "    optimizer = torch.optim.Adam(all_params, lr=lr)\n",
        "\n",
        "    # --- FASE 1: PRÉ-TREINAMENTO (DATASET FIXO) ---\n",
        "    fixed_df, fixed_tensor = create_fixed_dataset()\n",
        "    print(f\"Pré-Treinamento iniciado com {fixed_tensor.shape[0]} objetos fixos por {epochs_fixed} epochs...\")\n",
        "\n",
        "    if run_id == 0:\n",
        "        print(\"Gerando plotagem do cenário Fixo de Pré-Treinamento (Requisito 1)...\")\n",
        "        # Esta função irá exibir no Colab e tentar salvar/abrir em GUI se for o terminal,\n",
        "        # mas o backend 'Agg' deve evitar travamentos em terminais headless.\n",
        "        plot_scenario(fixed_df, \"Cenário Fixo de Pré-Treinamento (O1-O25) - Configuração Inicial\")\n",
        "\n",
        "    for epoch in range(epochs_fixed):\n",
        "        optimizer.zero_grad()\n",
        "        all_axioms_sat = compute_axioms(fixed_tensor, P)\n",
        "        loss = 1.0 - torch.mean(torch.stack(all_axioms_sat))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Pré-Treinamento Concluído (SatAgg Final Fixo: {1.0 - loss.item():.4f})\")\n",
        "\n",
        "    # --- FASE 2: TREINAMENTO PRINCIPAL (DATASET ALEATÓRIO) ---\n",
        "    data_df, dataset_tensor = generate_random_dataset(NUM_OBJECTS)\n",
        "    gt_Q1, gt_Q2 = calculate_ground_truth(data_df)\n",
        "\n",
        "    print(f\"Treinamento Principal iniciado com {dataset_tensor.shape[0]} objetos aleatórios por {epochs_random} epochs...\")\n",
        "\n",
        "    for epoch in range(epochs_random):\n",
        "        optimizer.zero_grad()\n",
        "        all_axiomas_sat = compute_axioms(dataset_tensor, P)\n",
        "        mean_sat = torch.mean(torch.stack(all_axiomas_sat))\n",
        "        loss = 1.0 - mean_sat\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    final_satisfaction = mean_sat.item()\n",
        "    print(f\"Treinamento Principal Concluído (SatAgg Final Aleatório: {final_satisfaction:.4f})\")\n",
        "\n",
        "    # Avaliação\n",
        "    for pred in Predicate.instances:\n",
        "        if pred.nn: pred.eval()\n",
        "    sat_results = calculate_formulas_sataag(dataset_tensor, P)\n",
        "\n",
        "    print(f\"GT Q1: {gt_Q1}, Pred Q1: {sat_results.get('Q1', 0.0):.4f} | GT Q2: {gt_Q2}, Pred Q2: {sat_results.get('Q2', 0.0):.4f}\")\n",
        "\n",
        "    return {\n",
        "        'Run': run_id + 1,\n",
        "        'SatAgg_Q1': sat_results.get('Q1', 0.0), 'SatAgg_Q2': sat_results.get('Q2', 0.0),\n",
        "        'GT_Q1': gt_Q1, 'Pred_Q1': sat_results.get('Q1', 0.0),\n",
        "        'GT_Q2': gt_Q2, 'Pred_Q2': sat_results.get('Q2', 0.0),\n",
        "        'SatAgg_F1': sat_results.get('F1', 0.0), 'SatAgg_F3': sat_results.get('F3', 0.0),\n",
        "        'SatAgg_F6': sat_results.get('F6', 0.0), 'SatAgg_Q3': sat_results.get('Q3_Axioma', 0.0),\n",
        "        'SatAgg_LastLeft': sat_results.get('lastOnTheLeft', 0.0), 'SatAgg_Existencial': sat_results.get('ConsultaExistencial', 0.0)\n",
        "    }\n",
        "\n",
        "# -------------------------------------------------------------------------------\n",
        "# 5. EXECUÇÃO PRINCIPAL E RELATÓRIO\n",
        "# -------------------------------------------------------------------------------\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    all_results = []\n",
        "\n",
        "    # Inicializa seeds para reprodutibilidade\n",
        "    random.seed(SEED)\n",
        "    np.random.seed(SEED)\n",
        "    torch.manual_seed(SEED)\n",
        "\n",
        "    for i in range(N_RUNS):\n",
        "        # Gera novas seeds para cada run, baseadas na SEED inicial\n",
        "        current_seed = SEED + i\n",
        "        random.seed(current_seed)\n",
        "        np.random.seed(current_seed)\n",
        "        torch.manual_seed(current_seed)\n",
        "\n",
        "        try:\n",
        "            run_data = run_experiment(i)\n",
        "            if run_data: all_results.append(run_data)\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Erro na execução {i+1}: {e}\", file=sys.stderr)\n",
        "            import traceback\n",
        "            traceback.print_exc(file=sys.stderr)\n",
        "\n",
        "    # Agregação e Relatório\n",
        "    if all_results:\n",
        "        results_df = pd.DataFrame(all_results)\n",
        "\n",
        "        metrics_q1 = calculate_metrics(results_df['GT_Q1'].tolist(), results_df['Pred_Q1'].tolist())\n",
        "        metrics_q2 = calculate_metrics(results_df['GT_Q2'].tolist(), results_df['Pred_Q2'].tolist())\n",
        "\n",
        "        # Cálculo das médias para a Análise do Raciocínio\n",
        "        mean_q1_sat = results_df['SatAgg_Q1'].mean()\n",
        "        mean_q2_sat = results_df['SatAgg_Q2'].mean()\n",
        "        mean_gt_q1 = results_df['GT_Q1'].mean()\n",
        "        mean_gt_q2 = results_df['GT_Q2'].mean()\n",
        "        mean_satagg = results_df[['SatAgg_F1', 'SatAgg_F3', 'SatAgg_F6', 'SatAgg_Q3',\n",
        "                                  'SatAgg_LastLeft', 'SatAgg_Existencial']].mean().to_frame('SatAgg Média').T\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"RELATÓRIO FINAL DO EXPERIMENTO LTN (5 EXECUÇÕES)\")\n",
        "        print(f\"LIMITES DE CENA: X={POS_RANGE_X}, Y={POS_RANGE_Y}\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        # 1. Tabela de SatAgg (Queries principais e Ground Truth)\n",
        "        print(\"\\n**1. Satisfatibilidade (SatAgg) das Queries Q1 e Q2 e Ground Truth (GT)**\")\n",
        "        satagg_table = results_df[['Run', 'SatAgg_Q1', 'GT_Q1', 'SatAgg_Q2', 'GT_Q2']]\n",
        "        satagg_table = satagg_table.round(4)\n",
        "        print(satagg_table.to_markdown(index=False))\n",
        "\n",
        "        # 2. Satisfatibilidade Média Agregada de Raciocínio (Axiomas e Queries Opcionais)\n",
        "        print(\"\\n**2. Satisfatibilidade Média Agregada de Raciocínio (Axiomas e Queries Opcionais)**\")\n",
        "        print(mean_satagg.round(4).to_markdown())\n",
        "\n",
        "        # 3. Métricas de Classificação\n",
        "        print(f\"\\n**3. Métricas de Classificação Agregadas (Limiar de Decisão: SatAgg > {SAT_THRESHOLD})**\")\n",
        "\n",
        "        metrics_data = {\n",
        "            'Métrica': ['Acurácia', 'Precisão', 'Recall', 'F1 Score'],\n",
        "            'Query 1 (Q1)': [metrics_q1['Acurácia'], metrics_q1['Precisão'], metrics_q1['Recall'], metrics_q1['F1 Score']],\n",
        "            'Query 2 (Q2)': [metrics_q2['Acurácia'], metrics_q2['Precisão'], metrics_q2['Recall'], metrics_q2['F1 Score']],\n",
        "        }\n",
        "        metrics_df = pd.DataFrame(metrics_data).set_index('Métrica').round(4)\n",
        "        print(metrics_df.to_markdown())\n",
        "\n",
        "        # 4. ANÁLISE DO RACIOCÍNIO (Explicação de cada pergunta)\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"4. ANÁLISE EXPLICATIVA DO RACIOCÍNIO LTN\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        # Análise da Q1\n",
        "        print(\"### Pergunta 1: Filtragem Composta\")\n",
        "        q1_formula_text = r'$\\exists x(\\text{IsSmall}(x) \\land \\exists y(\\text{IsCylinder}(y) \\land \\text{Below}(x, y)) \\land \\exists z(\\text{IsSquare}(z) \\land \\text{LeftOf}(x, z)))$'\n",
        "        print(f\"Fórmula: {q1_formula_text}\")\n",
        "        print(f\"GT Média: {mean_gt_q1:.2f} | SatAgg Média: {mean_q1_sat:.4f}\")\n",
        "\n",
        "        q1_analysis = f\"\"\"\n",
        "        Raciocínio: A rede deve encontrar um único objeto (x) que satisfaça três condições complexas simultaneamente: (1) ser Pequeno, (2) estar Abaixo de algum Cilindro, E (3) estar à Esquerda de algum Quadrado.\n",
        "\n",
        "        Conclusão: O valor de SatAgg Média ({mean_q1_sat:.4f}) é extremamente baixo e **inconsistente** com o Ground Truth ({mean_gt_q1:.2f}). A falha indica que a rede neural, apesar do alto SatAgg nos axiomas gerais, falhou em **combinar** com sucesso o predicado 'IsSmall' com os dois predicados relacionais ('Below' e 'LeftOf') em um único objeto 'x'. Isso sugere que a cadeia de raciocínio complexa não foi generalizada adequadamente no treinamento, resultando em F1 Score de {metrics_q1['F1 Score']:.4f}.\n",
        "        \"\"\"\n",
        "        print(textwrap.dedent(q1_analysis))\n",
        "\n",
        "        # Análise da Q2\n",
        "        print(\"### Pergunta 2: Dedução de Posição Absoluta\")\n",
        "        q2_formula_text = r'$\\exists x, y, z(\\text{IsCone}(x) \\land \\text{IsGreen}(x) \\land \\text{InBetween}(x, y, z))$'\n",
        "        print(f\"Fórmula: {q2_formula_text}\")\n",
        "        print(f\"GT Média: {mean_gt_q2:.2f} | SatAgg Média: {mean_q2_sat:.4f}\")\n",
        "\n",
        "        q2_analysis = f\"\"\"\n",
        "        Raciocínio: A rede deve provar a existência de um Cone de cor Verde que se localize 'Entre' quaisquer outros dois objetos (y e z). Como 'InBetween' é definido pela lógica horizontal ($\\text{{LeftOf}}$ e $\\text{{RightOf}}$), a prova depende de encontrar um Cone Verde que esteja horizontalmente entre outros dois.\n",
        "\n",
        "        Conclusão: O SatAgg Média ({mean_q2_sat:.4f}) é **extremamente baixo**, resultando em Acurácia de {metrics_q2['Acurácia']:.4f} e F1 Score de {metrics_q2['F1 Score']:.4f}. A falha é esperada, pois o predicado 'InBetween' é uma **fórmula lógica fixa** baseada em 'LeftOf' e 'RightOf'. A baixíssima satisfação reflete a dificuldade das NNs em aprender 'LeftOf' e 'RightOf' com precisão (transitividade e simetria) suficiente para satisfazer a lógica combinatória do predicado ternário 'InBetween'.\n",
        "        \"\"\"\n",
        "        print(textwrap.dedent(q2_analysis))\n",
        "\n",
        "        # Análise da Restrição de Proximidade (Q3 - como exemplo de sucesso)\n",
        "        print(\"### Restrição de Proximidade (Q3 - Axioma de Treinamento)\")\n",
        "        q3_formula_text = r'$\\forall x, y((\\text{IsTriangle}(x) \\land \\text{IsTriangle}(y) \\land \\text{CloseTo}(x, y)) \\Rightarrow \\text{SameSize}(x, y))$'\n",
        "        print(f\"Fórmula: {q3_formula_text}\")\n",
        "        print(f\"SatAgg Média (Fim do Treinamento): {mean_satagg.iloc[0]['SatAgg_Q3']:.4f}\")\n",
        "\n",
        "        q3_analysis = \"\"\"\n",
        "        Raciocínio: Este axioma força o modelo a correlacionar a posição espacial ('CloseTo', fixo pelo Kernel Gaussiano) com um atributo ('SameSize', um predicado neural). Se dois triângulos são próximos, o modelo é penalizado se eles não tiverem o mesmo tamanho.\n",
        "\n",
        "        Conclusão: O SatAgg alto (próximo a 1.0) demonstra que a rede neural **aprendeu com sucesso** a codificar a restrição de tamanho para triângulos próximos. O treinamento forçou o predicado 'SameSize' a ser consistente com a proximidade física.\n",
        "        \"\"\"\n",
        "        print(textwrap.dedent(q3_analysis))\n",
        "\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"EXPERIMENTO CONCLUÍDO.\")\n",
        "        print(\"=\"*80)\n",
        "    else:\n",
        "        print(\"\\nO experimento falhou em todas as execuções.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Resultados e Análise do Experimento (5 Execuções)\n",
        "\n",
        "---\n",
        "## RELATÓRIO FINAL DO EXPERIMENTO LTN (5 EXECUÇÕES)\n",
        "LIMITES DE CENA: X=38.0, Y=27.0\n",
        "---\n",
        "\n",
        "**1. Satisfatibilidade (SatAgg) das Queries Q1 e Q2 e Ground Truth (GT)**\n",
        "|   Run |   SatAgg_Q1 |   GT_Q1 |   SatAgg_Q2 |   GT_Q2 |\n",
        "|------:|------------:|--------:|------------:|--------:|\n",
        "|     1 |      0.0029 |       1 |      0.0029 |       1 |\n",
        "|     2 |      0.0028 |       1 |      0.0041 |       1 |\n",
        "|     3 |      0.0052 |       1 |      0.0047 |       1 |\n",
        "|     4 |      0.0024 |       1 |      0.0037 |       1 |\n",
        "|     5 |      0.0019 |       1 |      0.0019 |       1 |\n",
        "\n",
        "**2. Satisfatibilidade Média Agregada de Raciocínio (Axiomas e Queries Opcionais)**\n",
        "|              |   SatAgg_F1 |   SatAgg_F3 |   SatAgg_F6 |   SatAgg_Q3 |   SatAgg_LastLeft |   SatAgg_Existencial |\n",
        "|:-------------|------------:|------------:|------------:|------------:|------------------:|---------------------:|\n",
        "| SatAgg Média |      0.7347 |      0.9995 |      0.9033 |      0.9993 |            0.0005 |               0.9956 |\n",
        "\n",
        "**3. Métricas de Classificação Agregadas (Limiar de Decisão: SatAgg > 0.55)**\n",
        "| Métrica   |   Query 1 (Q1) |   Query 2 (Q2) |\n",
        "|:----------|---------------:|---------------:|\n",
        "| Acurácia  |              0 |              0 |\n",
        "| Precisão  |              0 |              0 |\n",
        "| Recall    |              0 |              0 |\n",
        "| F1 Score  |              0 |              0 |\n",
        "\n",
        "---\n",
        "## 4. ANÁLISE EXPLICATIVA DO RACIOCÍNIO LTN\n",
        "---\n",
        "### Pergunta 1: Filtragem Composta\n",
        "Fórmula: $\\exists x(\\text{IsSmall}(x) \\land \\exists y(\\text{IsCylinder}(y) \\land \\text{Below}(x, y)) \\land \\exists z(\\text{IsSquare}(z) \\land \\text{LeftOf}(x, z)))$\n",
        "GT Média: 1.00 | SatAgg Média: 0.0030\n",
        "\n",
        "Raciocínio: A rede deve encontrar um único objeto (x) que satisfaça três condições complexas simultaneamente: (1) ser Pequeno, (2) estar Abaixo de algum Cilindro, E (3) estar à Esquerda de algum Quadrado.\n",
        "\n",
        "Conclusão: O valor de SatAgg Média (0.0030) é extremamente baixo e **inconsistente** com o Ground Truth (1.00). A falha indica que a rede neural, apesar do alto SatAgg nos axiomas gerais, falhou em **combinar** com sucesso o predicado 'IsSmall' com os dois predicados relacionais ('Below' e 'LeftOf') em um único objeto 'x'. Isso sugere que a cadeia de raciocínio complexa não foi generalizada adequadamente no treinamento, resultando em F1 Score de 0.0000.\n",
        "\n",
        "### Pergunta 2: Dedução de Posição Absoluta\n",
        "Fórmula: $\\exists x, y, z(\\text{IsCone}(x) \\land \\text{IsGreen}(x) \\land \\text{InBetween}(x, y, z))$\n",
        "GT Média: 1.00 | SatAgg Média: 0.0035\n",
        "\n",
        "Raciocínio: A rede deve provar a existência de um Cone de cor Verde que se localize 'Entre' quaisquer outros dois objetos (y e z). Como 'InBetween' é definido pela lógica horizontal ($\\text{LeftOf}$ e $\\text{RightOf}$), a prova depende de encontrar um Cone Verde que esteja horizontalmente entre outros dois.\n",
        "\n",
        "Conclusão: O SatAgg Média (0.0035) é **extremamente baixo**, resultando em Acurácia de 0.0000 e F1 Score de 0.0000. A falha é esperada, pois o predicado 'InBetween' é uma **fórmula lógica fixa** baseada em 'LeftOf' e 'RightOf'. A baixíssima satisfação reflete a dificuldade das NNs em aprender 'LeftOf' e 'RightOf' com precisão (transitividade e simetria) suficiente para satisfazer a lógica combinatória do predicado ternário 'InBetween'.\n",
        "\n",
        "### Restrição de Proximidade (Q3 - Axioma de Treinamento)\n",
        "Fórmula: $\\forall x, y((\\text{IsTriangle}(x) \\land \\text{IsTriangle}(y) \\land \\text{CloseTo}(x, y)) \\Rightarrow \\text{SameSize}(x, y))$\n",
        "SatAgg Média (Fim do Treinamento): 0.9993\n",
        "\n",
        "Raciocínio: Este axioma força o modelo a correlacionar a posição espacial ('CloseTo', fixo pelo Kernel Gaussiano) com um atributo ('SameSize', um predicado neural). Se dois triângulos são próximos, o modelo é penalizado se eles não tiverem o mesmo tamanho.\n",
        "\n",
        "Conclusão: O SatAgg alto (próximo a 1.0) demonstra que a rede neural **aprendeu com sucesso** a codificar a restrição de tamanho para triângulos próximos. O treinamento forçou o predicado 'SameSize' a ser consistente com a proximidade física."
      ],
      "metadata": {
        "id": "WXvG1GPndIn-"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}